reward_variation
        
Reward changed in:
0 - reward = -SEx100
1 - reward = -AEx100

Experiment parameters were fixed:
    n_experiments=5,
    n_episodes=100,
    visualize=False,
    time_step=5,
    max_n_steps=40,
    p_reff=1.3,
    rand_qtab=False,
    learning_rate=0.5,
    discount_factor=0.6,
    k_s=[0.1, 0.5, 1, 2, 7],
    exploration_rate=0.5,
    exploration_decay_rate=0.9,   
    log_level=logging.INFO
        